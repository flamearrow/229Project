*) run the existing alrorithms once -done
	*) figure out how to run a small portion of testing data -done
		*) how data is read and split -done

*) convert our data into training data format -done

*) generate training data using pickle: https://www.python.org/doc/2.5/lib/module-cPickle.html -no need
    *) https://docs.python.org/3/library/pickle.html -done

*) this is models the paper for the cnn archetecture: https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf -done


*) figure out how to terminate from gradient descent -done
    *) can set max step

*) figure out how to use tensor board

*) learn this shit learningtensorflow.com

*) streamline the process:
    *) 880 picture-label as training data, 50 picture-label as test data
    *) convert these into training_data and test_data binary batches
    *) run the algorithm for X steps for training_data batch
    *) evaluate performance

*) stitch output back to a midi file

*) search for monotone midis like flute

*) how to select training data

*) projects
    *) three datasets(all use S0 without pedal)
       *) fft - 40 * 3 samples per note
       *) constant Q - 40 * 3 samples per note
       *) constant Q - 80 * 3 samples per note
       *) test/train - 4:1 (32/8 for 40 samples, 64/16 for 80 samples)
    *) plotting data:
       *) loss - time
       *) precision at certain loss
    *) try simplify the model, delete local layer

    *) in cs229_run, for top_k_op, try change it to some op to return actual predication
    *) train shit in sampleData, this is constantQ with higher frequency, nwo we have 80 samples per note

    *) model runner: cs229_run.py:
        *) does 2 things
            1) package raw datas into a binary data(output_data_packager.package_data_with_label_file())
            2) apply model(checkpoints) to the binary data to output corresponding labels

        *) copy data into these two folders:
            *) RAW_DATA_DIR: with unlabeled data pictures: 1.jpg, 2.jpg, ...
            *) --checkpoint_dir: data with checkpoint files

        *) Note for these two parameters:
            *) --num_examples: needs to be a multipy of 128, otherwise the programe will loop through the start of file to make sure it's a multipy of 128
                *) means you need to have 128 /256 ... jpg fileds, also change the file count to --num_examples
            *) PACKAGED_DATA_DIR: generated binary files for 1.jpg, 2.jpg... don't change this

        *) output: OUT_LABELS_FILE
            *) a file with corresponding label for 1.jpg, 2.jpg... on each line